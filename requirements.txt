# Core ML Libraries
torch>=2.1.0,<2.5.0
transformers>=4.36.0
datasets>=2.15.0
tokenizers>=0.15.0
accelerate>=0.25.0

# Parameter Efficient Fine-tuning
peft>=0.7.0
bitsandbytes>=0.41.0

# Experiment Tracking & Monitoring
mlflow>=2.8.1
wandb>=0.16.0
tensorboard>=2.15.0

# Data Processing & Validation
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
pydantic>=2.0.0
PyYAML>=6.0
datasets>=2.15.0

# Evaluation Metrics
evaluate>=0.4.0
seqeval>=1.2.2  # For NER evaluation
rouge-score>=0.1.2  # For summarization
sacrebleu>=2.3.1  # For translation

# Web Interface
streamlit>=1.28.0
flask>=2.3.0
plotly>=5.17.0
gradio>=4.0.0

# Optimization & Performance
flash-attn>=2.3.0; platform_machine != "arm64"  # Skip on ARM/M1 Macs
triton>=2.1.0; platform_machine != "arm64"
xformers>=0.0.22

# Utilities
tqdm>=4.66.0
rich>=13.7.0  # Better CLI output
typer>=0.9.0  # CLI framework
python-dotenv>=1.0.0
requests>=2.31.0
psutil>=5.9.0

# Development & Testing
pytest>=7.4.0
pytest-cov>=4.1.0
black>=23.9.0
isort>=5.12.0
flake8>=6.0.0
mypy>=1.7.0
pre-commit>=3.5.0

# Documentation
mkdocs>=1.5.0
mkdocs-material>=9.4.0
sphinx>=7.2.0

# Cloud & Deployment
boto3>=1.34.0  # AWS
google-cloud-storage>=2.10.0  # GCP
azure-storage-blob>=12.19.0  # Azure
kubernetes>=28.1.0

# Optional: Specific model support
# sentence-transformers>=2.2.0  # For embedding models
# llama-cpp-python>=0.2.0  # For Llama.cpp integration
# ctransformers>=0.2.0  # For GGML models

# Pin specific versions for reproducibility
setuptools>=68.0.0,<71.0.0  # Avoid conflicts with newer versions
wheel>=0.41.0
pip>=23.3.0